# Wikipedia data for NLP tasks and Data Visualization

## Data preparation

English wiki latest:
https://dumps.wikimedia.org/enwiki/latest/ (20G compressed, 80G after uncompressing)

Kaggle wiki plain text:
https://www.kaggle.com/datasets/jjinho/wikipedia-20230701/data (13G compressed, 15G after uncompressing)

Simple wiki:
https://github.com/daveshap/PlainTextWikipedia

Wikipedia extractor:
https://wiki.apertium.org/wiki/Wikipedia_Extractor

Wikipedia chinese:
http://licstar.net/archives/262

## Search Engine and Recommendation System

Bitjoy's blog:
https://bitjoy.net/2016/01/09/introduction-to-building-a-search-engine-7/

Stanford information retrieval:
https://nlp.stanford.edu/IR-book/

Overview of Search System Kernel Technology
https://juejin.cn/post/7033227795996246052


## Planned tasks

### Display the evolution process of world history
- On a map
- Show the wars
- Show the population
- Show important events

### Common sense knowledge bot
- Dense knowledge retrieval


### Search Engine
- All kinds of retrieval methods

### Knowledge graph

- Knowledge graph is dead
- common ways to store information is dead
- we need ways to compress information instead
- human brain is not a database, but a model (dense or not)


...

...

...



